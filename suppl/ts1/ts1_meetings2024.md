---
layout: default
---

## [Selected Topics on Machine and Deep Learning (STMDL), 2024](/suppl/ts1/ts1_main2024)

### Meetings
This is the course schedule:

* Week 1 (03/06) - Least Squares
  * [rec](https://sce-ac-il.zoom.us/rec/share/6Mn5qDiVPxjnEI2Os2IsYAtvri7RhztjGd0px34koqT81JwUAZ9RdO2hZAZ2Bvtp.Lsr0bY1nVdmY3HDA?startTime=1717420436000), [notes](/suppl/ts1/Lec2024/Lec1 - Introduction & LS.pdf), [code-m](/suppl/ts1/Lec2024/ls_regression.m), [code-mlx](/suppl/ts1/Lec2024/ls_regression2.mlx) 
  * Supplementary videos: [Linear Least Squares](https://www.youtube.com/watch?v=pKAPgUb4vL8), [Khan Academy](https://www.khanacademy.org/math/ap-statistics/bivariate-data-ap/xfb5d8e68:residuals/v/regression-residual-intro) 

* Week 2: 10/06 - Model Evaluation
  * [rec](https://sce-ac-il.zoom.us/rec/share/Fjo2i2n1dU33UEu5PmDJOwqz8_XWNQ_Ti-kxuvME_C9VMuzX-KhwcuPNWV67dWJp.X-ymEI9upcfR2D8u?startTime=1718025332000), [notes](/suppl/ts1/Lec2024/Lec2 - Model Characterization and Tuning.pdf), [code-m](/suppl/ts1/Lec2024/linear_fit_poly_example.m)
  * Homework [data](/suppl/ts1/Lec2024/poly_regression.zip). Each student should use different dataset for the best $$N$$ value evaluation.

* Week 3: 17/06 - Overfitting management: Regularization, standardization
  * [rec](https://sce-ac-il.zoom.us/rec/share/UzXzrMpuswtuh1xdAMBM15_nm6rlJUp4wS4rIw6-Y-26dF_meiwwkO0mnFvR07bL._5vzV5fG_pV1S4Bx?startTime=1718630065000)
  * [notes](/suppl/ts1/Lec2024/Lec3 - Overfitting management.pdf), 
  * [code-m](/suppl/ts1/Lec2024/linear_fit_poly_reg.m)

* Week 4: 24/06 - Kernel regression
  * [rec](https://sce-ac-il.zoom.us/rec/share/uqF1CVFNIXCi_dkYZGzGiyPI_rQc453vlkjQQVxA46J6_Q6s088ZZglodcrdo8x8.WtMGlF63aHwfOWid?startTime=1719235080000)
  * [notes](/suppl/ts1/Lec2024/Lec4 - Kernels.pdf),
  * [code-m](/suppl/ts1/Lec2024/kernel_example.m), [code-m](/suppl/ts1/Lec2024/kernel_s_example.m)

* Week 5: 01/07 - Regression metrics and losses
  * References:
    * A survey and taxonomy of loss functions in machine learning ([arXiv](https://arxiv.org/abs/2301.05579))
    * A Comprehensive Overview of Regression Evaluation Metrics ([Nvidia](https://developer.nvidia.com/blog/a-comprehensive-overview-of-regression-evaluation-metrics/))
    * [5 Regression Loss Functions All Machine Learners Should Know](https://heartbeat.fritz.ai/5-regression-loss-functions-all-machine-learners-should-know-4fb140e9d4b0)
    * [Mean Squared Logarithmic Error Loss](https://insideaiml.com/blog/MeanSquared-Logarithmic-Error-Loss-1035)
    * [Huber and logcosh loss functions](https://jiafulow.github.io/blog/2021/01/26/huber-and-logcosh-loss-functions/)
    * Dealing with Outliers Using Three Robust Linear Regression Models ([Nvidia](https://developer.nvidia.com/blog/dealing-with-outliers-using-three-robust-linear-regression-models/))
  * [notes](/suppl/ts1/Lec2024/Lec5 - Regression Losses.pdf)
  * [rec](https://sce-ac-il.zoom.us/rec/share/t6uUs3M4CCcNaRITGUqSq-xDBOGxtjdI1gR5eBKEAce68IR8O2TDj2Sq-AxLbjs5.LBCM1ZGSLfFqS10j)
  * [code-m](/suppl/ts1/Lec2024/mae_loss_example.m)

* Week 6: 08/07 - Classification and logistic regression, k-NN
  * [rec](https://sce-ac-il.zoom.us/rec/share/e7f1oBqeSby7V9YVIxAW2CqlHKJC-AJIg-Sb_sClBOm2uwU1UJ4nmK79hRHAPAjA.GDoAY8Ir1J51GJEW?startTime=1720444604000)
  * [notes](/suppl/ts1/Lec2024/Lec6 - Classification.pdf)
  * [code-m](/suppl/ts1/Lec2024/logistic_regression.zip)

* Week 7: 15/07 - Classification metrics
  * Reference: [Classification Performance](https://developers.google.com/machine-learning/crash-course/classification) by Google 
  * [rec](https://sce-ac-il.zoom.us/rec/share/_rj5zvGT3YQFL_Nk2IsJ1lSpSMETlGlLHNnklT-VNHJxNod4gr5eLM2GP9zqfuUc.6vgoTVVifw4_iE9V)
  * [notes](/suppl/ts1/Lec2024/Lec7 - Classification Performance.pdf)
  * updated `logistic_regression_2d_example.m` from logistic regression [code-m](/suppl/ts1/Lec2024/logistic_regression.zip)

* Week 8: 22/07 - Signal classification: feature extraction and selection
  * [rec](https://sce-ac-il.zoom.us/rec/share/NFe9Y6QDzDeSB3VV48GW-XI2Mflg5XT7pfsm5bEOXT3nx1eoJ4gcFr3kklma0qvb.NNfud5urgEsVXLdl?startTime=1721654006000)
  * [notes](/suppl/ts1/Lec2024/Lec8 - Feature extraction.pdf)

* Week 9: 29/07 - Plotting, visualization and PCA
  * [rec](https://sce-ac-il.zoom.us/rec/share/KWCu9m4WUfRWBx36WBCMClYL2REp1zl8Pdeb3KEFy-Don6UA2OUrjkoZy2CtwQA6.rNl-2m7OYSMFAypK?startTime=1722864488000)
  * [notes](/suppl/ts1/Lec2024/Lec9 - PCA.pdf)
  * [code-Ellipse](/suppl/ts1/Lec2024/ellipse_example.m)
  * [code-PCA-compression](/suppl/ts1/Lec2024/pca_compression.m), [code-PCA](/suppl/ts1/Lec2024/pca_compression.m)
  * [code-PCA-Iris](/suppl/ts1/Lec2024/pca_iris.m)
  * [code-Plots](/suppl/ts1/Lec2024/plots.mlx)
  * Reference: [Anscombe's quartet](https://en.wikipedia.org/wiki/Anscombe%27s_quartet)
  * Reference: [Colormap](https://www.mathworks.com/help/matlab/ref/colormap.html)




