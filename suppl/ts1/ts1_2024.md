---
layout: default
toc:
  sidebar: left
---

## Selected topics on machine and deep learning (SMDL), 2024
* This is the official page of the graduate-level SMDL course, 2024. 
* This page is used for course information and materials.
* The complementary Moodle page is used for course communication and submissions. 

---
### Grading
Final grade calculation:
* 40% - 5 MOOC certificates, each 8% of the final grade
* 20% - presentation
* 40% - homeworks
---

### MOOC certificates
A certificate of completion of the following online courses (MOOC) is required for the course completion:
* Kaggle learn [Python](https://www.kaggle.com/learn/python)
* Kaggle learn [Pandas](https://www.kaggle.com/learn/pandas) 
* Kaggle learn [Intro to Machine Learning](https://www.kaggle.com/learn/intro-to-machine-learning)
* Kaggle learn [Intermediate Machine Learning](https://www.kaggle.com/learn/intermediate-machine-learning)
* Kaggle learn [Feature Engineering](https://www.kaggle.com/learn/feature-engineering)

---

### Presentation
Each student is required to present a python package or a library that are used for machine learning or deep learning of signals:
* The presentation is scheduled for the last week of the course.
* The presentation is 30 minutes long.
* The presentation is graded based on the content and the presentation skills.
* The presentation includes:
  * Briefly introduce the package and its purpose. Explain why itâ€™s relevant and how it can benefit developers.
  * Explain the package/library philosophy.
  * Explain the package/library special capabilities and features.
  * Hands-on example - a Jupyter notebook with a practical example of the package/library usage.
The supplementary materials to be submitted in advance of the presentation include: 
* Presentation slides
* Summary - 2 pages, with emphasis on:
  * The package/library philosophy
  * The package/library special capabilities
* Hands-on example - a Jupyter notebook with a simple example of the package/library usage.
* Package/library list:
  * Recommended packages - feature extraction:
    * [tsfresh](https://tsfresh.readthedocs.io/en/latest/) - Feature extraction from time series
    * [catch22](https://time-series-features.gitbook.io/catch22-features/) - A Python package for time series characterization and feature extraction
    * [hctsa](https://github.com/benfulcher/hctsa) - Highly Comparative Time-Series Analysis (HCTSA) feature extraction package
  * Recommended packages - time series analysis:
      * [pyts](https://pyts.readthedocs.io/en/stable/index.html) - A Python Package for Time Series Classification
      * [tslearn](https://tslearn.readthedocs.io/en/stable/) -  Machine learning tools for the analysis of time series      
      * [tsai](https://timeseriesai.github.io/tsai/) - A state-of-the-art deep learning library for time series and sequential data
      * [scale-cast](https://github.com/mikekeith52/scalecast) - A Python package for time series forecast
      * [ml-forecast](https://github.com/Nixtla/mlforecast) - Scalable machine learning for time series forecasting
      * [prophet](https://facebook.github.io/prophet/) - A forecasting procedure implemented in R and Python
      * [TF-1D-2D](https://github.com/Sakib1263/TF-1D-2D-Segmentation-End2EndPipelines) - TensorFlow 1D and 2D models
  * The following packages are not allowed for the presentation since they are not maintained:
      * [seglearn](https://dmbee.github.io/seglearn/) - A Python package for time series classification
  * Any other package/library can be proposed for the instructor approval.

### Homeworks
* All homeworks are mandatory except one
* Submission is via the Moodle page
* The homeworks are graded based on the following criteria:
  * The correctness of the solution (25%)
  * The quality of the code (25%)
  * The quality of the explanation and comments (25%)
  * Formatting (25%)
    * Plots are required to be labeled and have a title
    * Multi-level headings are required
* The code is required to be submitted as a Jupyter notebook
* The code is required to be submitted as a PDF file

---

### Meetings
This is the course schedule:
| Week | Date  | Topic                                     |
| :---: | :---: | :--------------------------------------- |
| 1    | 03/06 | Linear regression                         |
| 2    | 10/06 | Nonlinear regression                      |
| 3    | 17/06 | Model characterization and tuning         |
| 4    | 24/06 | Kernels                                   |
| 5    | 01/07 | Regression metrics                        |
| 6    | 08/07 | Logistic regression and gradient descent  |
| 7    | 15/07 | Binary-cross entropy (BCE)                |
| 8    | 22/07 | Classification metrics                    |
| 9    | 29/07 | Introduction to neural networks           |
| 10   | 05/08 | Introduction to deep neural networks      |
| 11   | 12/08 | Introduction to recursive neural networks |
| 12   | 19/08 | Student presentations                     |